{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install albumentations --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    " \n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "# %pip install --force-reinstall pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as album\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U segmentation-models-pytorch albumentations > /dev/null\n",
    "# !pip install segmentation-models-pytorch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_path = \"data/images/M-33-7-A-d-2-3.tif\"\n",
    "\n",
    "# Load image\n",
    "\n",
    "image = cv2.imread(imagem_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem_path = \"data/masks/M-33-7-A-d-2-3.tif\"\n",
    "\n",
    "# Load mask\n",
    "mask = cv2.imread(imagem_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/patches'\n",
    "\n",
    "# ler as pastas masks e images e criar um csv com os caminhos\n",
    "def create_df(data_path):\n",
    "    data = []\n",
    "    index = 0\n",
    "    for image in os.listdir(data_path):\n",
    "      # se a imagem tiver _m antes do .png, é uma máscara\n",
    "      if '_m' in image:\n",
    "        mask_path = os.path.join(data_path, image)\n",
    "        sat_image = image.replace('_m', '')\n",
    "        sat_image = sat_image.replace('.png', '.jpg')\n",
    "        sat_image_path = os.path.join(data_path, sat_image)\n",
    "        data.append([index, sat_image_path, mask_path])\n",
    "        index += 1\n",
    "    return pd.DataFrame(data, columns=['image_id', 'dat_image_path', 'mask_path'])\n",
    "  \n",
    "df = create_df(DATA_DIR)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar o csv\n",
    "df.to_csv('metadata_patches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(df['mask_path'][110], cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels:\n",
    "# 0: Unlabeled background ​\n",
    "# 1: Buildings​\n",
    "# 2: Woodlands​\n",
    "# 3: Water​\n",
    "\n",
    "# create csv with the labels\n",
    "def create_label_csv():\n",
    "    data = [[0, 'Unlabeled background'], [1, 'Buildings'], [2, 'Woodlands'], [3, 'Water']]\n",
    "    return pd.DataFrame(data, columns=['label', 'name'])\n",
    "  \n",
    "label_df = create_label_csv()\n",
    "label_df.to_csv('class_dict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eu tenho um txt com todas as imagens que são para treino, crie um dataframe com essas imagens\n",
    "def create_train_df(data_path, txt_path):\n",
    "    train_images = []\n",
    "    with open(txt_path, 'r') as file:\n",
    "        for line in file:\n",
    "            image = line.strip()\n",
    "            mask_path = os.path.join(data_path, f'{image}_m.png')\n",
    "            image_path = os.path.join(data_path, f\"{image}.jpg\")\n",
    "            train_images.append([image_path, mask_path])\n",
    "    return pd.DataFrame(train_images, columns=['image', 'mask_path'])\n",
    "  \n",
    "train_df = create_train_df(DATA_DIR, 'data/train.txt')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_df(data_path, txt_path):\n",
    "    test_images = []\n",
    "    with open(txt_path, 'r') as file:\n",
    "        for line in file:\n",
    "            image = line.strip()\n",
    "            mask_path = os.path.join(data_path, f'{image}_m.png')\n",
    "            image_path = os.path.join(data_path, f\"{image}.jpg\")\n",
    "            test_images.append([image_path, mask_path])\n",
    "    return pd.DataFrame(test_images, columns=['image', 'mask_path'])\n",
    "  \n",
    "test_df = create_test_df(DATA_DIR, 'data/test.txt')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_valid_df(data_path, txt_path):\n",
    "    valid_images = []\n",
    "    with open(txt_path, 'r') as file:\n",
    "        for line in file:\n",
    "            image = line.strip()\n",
    "            mask_path = os.path.join(data_path, f'{image}_m.png')\n",
    "            image_path = os.path.join(data_path, f\"{image}.jpg\")\n",
    "            valid_images.append([image_path, mask_path])\n",
    "    return pd.DataFrame(valid_images, columns=['image', 'mask_path'])\n",
    "  \n",
    "valid_df = create_valid_df(DATA_DIR, 'data/val.txt')\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train size: {train_df.shape[0]}\")\n",
    "print(f\"Test size: {test_df.shape[0]}\")\n",
    "print(f\"Validation size: {valid_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class LandcoverDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "      image_path = self.df['image'].iloc[idx]\n",
    "      mask_path = self.df['mask_path'].iloc[idx]\n",
    "      \n",
    "      image = cv2.imread(image_path)\n",
    "      mask = cv2.imread(mask_path)\n",
    "\n",
    "      if self.transform:\n",
    "          label = mask[:, :, 1]\n",
    "          transformed = self.transform(image=image, mask=label)\n",
    "          img = np.transpose(transformed[\"image\"], (2, 0, 1))\n",
    "          label = transformed[\"mask\"]\n",
    "      else:\n",
    "          img = np.transpose(image, (2, 0, 1))\n",
    "          label = mask[:, :, 1]\n",
    "\n",
    "      # Adicionar dimensão extra para a máscara\n",
    "      label = np.expand_dims(label, axis=0)\n",
    "      \n",
    "      del mask\n",
    "      return torch.tensor(img, dtype=torch.float32) / 255, torch.tensor(label, dtype=torch.int64)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation ():\n",
    "    train_transform = [\n",
    "        album.OneOf([\n",
    "            album.HueSaturationValue(40,40,30,p=1),\n",
    "            album.RandomBrightnessContrast(p=1,brightness_limit = 0.2,\n",
    "                                        contrast_limit = 0.5)], p = 0.5),\n",
    "        album.OneOf([\n",
    "            album.RandomRotate90(p=1),\n",
    "            album.HorizontalFlip(p=1),\n",
    "            album.RandomSizedCrop(min_max_height=(248,512),height=512,width=512, p =1)\n",
    "            ], p = 0.5)\n",
    "    ]\n",
    "    return album.Compose(train_transform)\n",
    "  \n",
    "ENCODER = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['buildings', 'woodlands', 'water', 'background', 'road']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = LandcoverDataset(train_df, transform = get_augmentation())\n",
    "test_set = LandcoverDataset(test_df)\n",
    "valid_set = LandcoverDataset(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dloader = DataLoader(train_set, batch_size = batch_size,\n",
    "                           shuffle = True, num_workers = 0)\n",
    "test_dloader = DataLoader(test_set, batch_size = batch_size, num_workers = 0)\n",
    "val_dloader = DataLoader(valid_set, batch_size=batch_size, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentation model with pretrained encoder\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=5e-5),\n",
    "])\n",
    "\n",
    "loss = smp.losses.JaccardLoss(mode = \"multiclass\",\n",
    "                                classes = 5).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "def training_loop(model, train_loader, val_loader, epochs, lr, loss_fn, early_stopping = False, patience = None, model_title = None, save = None, stopping_criterion = \"loss\"):\n",
    "    if stopping_criterion not in [\"loss\",\"IoU\"]:\n",
    "        raise ValueError(f\"Critério de parada deve ser 'loss' ou 'IoU', nao {stopping_criterion}.\")\n",
    "    print(\"Treinamento de \" + model_title + \" iniciou!\")\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    optim = Adam(model.parameters(), lr=lr)\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        \n",
    "    if stopping_criterion == \"IoU\":\n",
    "        jaccard = torchmetrics.JaccardIndex(num_classes = 5).to(device)\n",
    "\n",
    "        iou_loss_list = []\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    num_train_batches = len(train_loader)\n",
    "    num_val_batches = len(val_loader)\n",
    "    counter_epochs = 0\n",
    "\n",
    "    if early_stopping:\n",
    "        ear_stopping = EarlyStopping(patience= patience)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        counter_epochs+=1\n",
    "        model.train()\n",
    "        train_loss, val_loss = 0.0, 0.0\n",
    "        \n",
    "        if stopping_criterion == \"IoU\": iou_loss = 0.0 \n",
    "        for train_batch in train_loader:\n",
    "            X, y = train_batch[0].to(device), train_batch[1].to(device)\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, y)\n",
    "            train_loss += loss.item()\n",
    "            if stopping_criterion == \"IoU\":\n",
    "                iou_loss += 1- float(jaccard(preds, y).cpu())\n",
    "\n",
    "            # Backpropagation\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                X, y = val_batch[0].to(device), val_batch[1].to(device)\n",
    "                preds = model(X)\n",
    "                if stopping_criterion == \"loss\":\n",
    "                    val_loss += loss_fn(preds, y).item()\n",
    "                else:\n",
    "                    # Calculate the 1-IoU as validation loss\n",
    "                    val_loss += 1-float(jaccard(preds,y).cpu())\n",
    "        train_loss /= num_train_batches\n",
    "        val_loss /= num_val_batches\n",
    "        if stopping_criterion == \"IoU\":\n",
    "            iou_loss /= num_train_batches\n",
    "            iou_loss_list.append(iou_loss)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        if stopping_criterion == \"loss\":\n",
    "            print(\n",
    "                f\"ÉPOCA: {epoch + 1}/{epochs}{5 * ' '} \n",
    "                Loss de treino: {train_loss:.4f}{5 * ' '} \n",
    "                Loss de validacao: {val_loss:.4f}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"ÉPOCA: {epoch + 1}/{epochs}{5 * ' '} \n",
    "                IoU Loss de treino: {iou_loss:.4f}{5 * ' '} \n",
    "                IoU Loss de validacao: {val_loss:.4f}{5*' '} \n",
    "                Loss de treino: {train_loss:.4f}\")\n",
    "                \n",
    "                \n",
    "\n",
    "        if early_stopping:\n",
    "            ear_stopping(val_loss, model)\n",
    "            if ear_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    sns.set_style(\"dark\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    if stopping_criterion == \"loss\":\n",
    "        ax.plot(range(1, counter_epochs + 1), train_loss_list, label='Train Loss',\n",
    "               color = \"#808080\", linewidth = 2.5)\n",
    "    else:\n",
    "        ax.plot(range(1, counter_epochs + 1), iou_loss_list, label='Train IoU Loss',\n",
    "               color = \"#808080\", linewidth = 2.5)\n",
    "    ax.plot(range(1, counter_epochs + 1), val_loss_list, label='Val Loss',\n",
    "            color = \"#36454F\", linewidth = 2.5)\n",
    "    ax.set_title(model_title, fontsize = 15)\n",
    "    ax.set_ylabel(\"Loss\", fontsize = 13)\n",
    "    ax.set_xlabel(\"Epochs\", fontsize = 13)\n",
    "    plt.legend()\n",
    "    if save is not None:\n",
    "        plt.savefig(model_title + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "    if early_stopping:\n",
    "        model.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "    total_time = time.time() - tic\n",
    "    mins, secs = divmod(total_time, 60)\n",
    "    if mins < 60:\n",
    "        print(f\"\\n Training completed in {mins} m {secs:.2f} s.\")\n",
    "    else:\n",
    "        hours, mins = divmod(mins, 60)\n",
    "        print(f\"\\n Training completed in {hours} h {mins} m {secs:.2f} s.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 50 epochs\n",
    "EPOCHS = 50\n",
    "lr = 5e-5\n",
    "\n",
    "training_loop(model, train_dloader, val_dloader, EPOCHS, lr, loss, mod_epochs =1, early_stopping = True, patience = 5, model_title = \"DeepLabV3+ with Resnet50 encoder\", save = True, stopping_criterion = \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.DeepLabV3Plus(encoder_name = \"resnet50\",\n",
    "                         encoder_weights = \"imagenet\",\n",
    "                         decoder_atrous_rates = (12,18,24),\n",
    "                         encoder_output_stride =16,\n",
    "                         classes = 5).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"checkpoint.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "labels_cmap = mpl.colors.ListedColormap([\"#000000\", \"#A9A9A9\",\n",
    "        \"#8B8680\", \"#D3D3D3\", \"#FFFFFF\"])\n",
    "\n",
    "\n",
    "indices = np.random.randint(low = 0, high = len(train_set), size = 4)\n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(figsize = (12,12), nrows = 4, ncols = 3)\n",
    "model.eval()\n",
    "\n",
    "for i,idx in enumerate(indices):\n",
    "    X,y = train_set[idx]\n",
    "    X_dash = X[None,:,:,:].to(DEVICE)\n",
    "    preds = torch.argmax(model(X_dash), dim = 1)\n",
    "    preds = torch.squeeze(preds).detach().cpu().numpy()\n",
    "\n",
    "    ax[i,0].imshow(np.transpose(X.cpu(), (2,1,0)))\n",
    "    ax[i,0].set_title(\"True Image\")\n",
    "    ax[i,0].axis(\"off\")\n",
    "    ax[i,1].imshow(y, cmap = labels_cmap, interpolation = None,\n",
    "                  vmin = -0.5, vmax = 4.5)\n",
    "    ax[i,1].set_title(\"Labels\")\n",
    "    ax[i,1].axis(\"off\")\n",
    "    ax[i,2].imshow(preds, cmap = labels_cmap, interpolation = None,\n",
    "                  vmin = -0.5, vmax = 4.5)\n",
    "    ax[i,2].set_title(\"Predictions\")\n",
    "    ax[i,2].axis(\"off\")\n",
    "fig.suptitle(\"Predictions - DeepLabV3+\", fontsize = 20)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"DeepLabV3+.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
